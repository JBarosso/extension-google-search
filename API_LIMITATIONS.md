# Limitations de l'API Google Search Console & Solutions

Ce document explique les contraintes techniques impos√©es par Google concernant la r√©cup√©ration des erreurs d'indexation et la solution mise en place.

## üî¥ Le Probl√®me : R√©cup√©rer la liste des erreurs (404, 500...)

Il est **impossible** via l'API publique actuelle (`Google Search Console API v3`) de r√©cup√©rer la liste compl√®te des URLs en erreur (le rapport "Pages" ou "Couverture" visible dans l'interface GSC).

### Pourquoi ?
*   Google a **supprim√©** les endpoints permettant de lister les "Crawl Errors" il y a plusieurs ann√©es.
*   Ces donn√©es sont r√©serv√©es √† l'interface web de la Search Console ou √† l'export manuel (CSV/Excel).
*   L'API ne fournit que les **Performances** (Clics, Impressions) et les **Sitemaps**.

### Ce que l'API NE PEUT PAS faire :
*   ‚ùå "Donne-moi toutes les pages en 404 sur mon site".
*   ‚ùå "Liste toutes les pages exclues par la balise noindex".
*   ‚ùå "Donne-moi les erreurs serveur (5xx)".

---

## üü¢ La Solution : L'Inspecteur d'URL (URL Inspection API)

Pour contourner cette limitation, nous avons impl√©ment√© un **Inspecteur d'URL**.

### Principe
Au lieu de demander √† Google "Quelles sont mes erreurs ?", nous lui donnons une liste d'URLs (par exemple issues de votre Sitemap ou d'un crawl Screaming Frog) et nous lui demandons : "**Quel est le statut de CETTE url ?**".

### Comment l'utiliser avec l'extension ?
1.  **R√©cup√©rez vos URLs** : Exportez votre Sitemap ou la liste de vos pages depuis votre CMS/Crawler.
2.  **Collez-les dans l'extension** : Onglet "Inspecteur".
3.  **Lancez l'analyse** : L'extension va interroger Google pour chaque URL.
4.  **R√©sultat** : Vous obtiendrez le statut pr√©cis pour chaque ligne (Index√©e, Non index√©e, Erreur 404 d√©tect√©e par Google, etc.).

### Quotas & Limites
*   L'API d'inspection est limit√©e √† **2 000 requ√™tes par jour** et par propri√©t√©.
*   L'outil est donc id√©al pour v√©rifier des lots d'URLs sp√©cifiques ou des nouvelles pages, mais pas pour auditer un site de 100 000 pages en une fois (pour cela, l'export BigQuery est n√©cessaire).
